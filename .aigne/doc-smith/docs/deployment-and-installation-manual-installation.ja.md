# 概要

![logo.svg](../../../blocklets/core/src/logo.svg)

AIGNE Hub は、多様な大規模言語モデル (LLM) および AI 生成コンテンツ (AIGC) プロバイダーへの接続管理を効率化するために設計された、統合 AI ゲートウェイです。異なる API キーの取り扱いの複雑さを抽象化し、使用状況を監視し、複数の AI サービスにまたがる請求を統合します。AIGNE エコシステムの中核コンポーネントとして、すべての生成 AI オペレーションの中枢神経系として機能し、AIGNE フレームワーク、AIGNE Studio、または AIGNE CLI で構築されたアプリケーションに、堅牢でスケーラブルなバックボーンを提供します。

## 主な機能

AIGNE Hub は、オペレーショナルエクセレンスを実現するために設計されており、DevOps、SRE、およびインフラストラクチャチームが AI サービスを効率的かつ安全に展開、管理、監視するために必要なツールを提供します。

*   **セルフホスティングによる完全なコントロール**: 自身のインフラストラクチャ内に AIGNE Hub を展開することで、データ、セキュリティ、および運用に対する完全な権限を確保します。このモデルにより、すべてのデータがセキュリティ境界内に留まり、厳格なコーポレートガバナンスとコンプライアンス基準に準拠することが保証されます。
*   **一元化されたマルチプロバイダーアクセス**: 8社以上の主要な AI プロバイダーと、単一の統合インターフェースを通じて統合します。これにより、複数の統合ポイントが不要になり、構成管理が簡素化され、多数のサービス接続を維持するための運用オーバーヘッドが削減されます。
*   **統合されたセキュリティとアクセス制御**: 暗号化された API キー ストレージで機密性の高い認証情報を安全に管理します。AIGNE Hub は、きめ細かなロールベースのアクセス制御を提供し、セキュリティポリシーを適用し、チームやアプリケーション全体の権限を一元的に管理することができます。
*   **包括的な使用状況分析**: 詳細な追跡とコスト分析により、AI サービスの消費に関する深い洞察を得ることができます。使用パターンを監視し、プロバイダーまたはモデルごとの支出を追跡し、リソース割り当てを最適化してコストを効果的に管理します。
*   **柔軟な請求とサービスの収益化**: 内部コスト追跡のためにハブを運用するか、顧客向けのサービスとして展開します。内蔵のクレジットシステムと Payment Kit との統合により、カスタム価格設定、利益率の適用、さまざまなユーザーグループの請求サイクルの管理が可能です。
*   **シームレスな AIGNE エコシステム統合**: AIGNE Hub は、AIGNE フレームワークとすぐに連携できるように構築されており、摩擦のない開発体験を提供します。そのアーキテクチャにより、エコシステム内のどのアプリケーションも、複雑な設定なしにその機能を活用できます。

## コア機能

AIGNE Hub は、高スループットかつ低遅延のオペレーション向けに設計された、標準化された RESTful API を介してアクセス可能な、堅牢で本番環境に対応した一連の機能を提供します。

| 機能 | 説明 |
| :--- | :--- |
| ![icon-text.svg](../../../blocklets/core/src/icons/icon-text.svg) **チャット補完** | 幅広い自然言語処理タスクのために、対話型 AI と高度なテキスト生成モデルへのアクセスを提供します。 |
| ![icon-image.svg](../../../blocklets/core/src/icons/icon-image.svg) **画像生成** | 主要な AI 画像生成・編集モデルと統合し、ビジュアルコンテンツの動的な作成と操作を可能にします。 |
| ![icon-embedding.svg](../../../blocklets/core/src/icons/icon-embedding.svg) **埋め込み** | セマンティック検索、クラスタリング、その他の機械学習アプリケーションで使用するために、テキストのベクトル表現を生成します。 |

## 対応 AI プロバイダー

AIGNE Hub は、主要な AI プロバイダーの増え続けるリストをサポートしており、さまざまなパフォーマンスとコストの要件に合わせて幅広いモデルの選択肢を提供します。このマルチプロバイダー戦略により、回復力と柔軟性が確保され、アプリケーションを再設計することなく、モデルやプロバイダーを切り替えることができます。

*   OpenAI (GPT モデル, DALL-E, 埋め込み)
*   Anthropic (Claude モデル)
*   Amazon Bedrock
*   Google Gemini
*   DeepSeek
*   Ollama (ローカルモデル展開)
*   OpenRouter
*   xAI (Grok モデル)
*   Doubao
*   Poe

## 展開シナリオ

AIGNE Hub は、さまざまな組織のニーズや運用コンテキストに対応するため、2つの主要な展開モデルをサポートするように設計されています。

### エンタープライズセルフホスティング

このシナリオは、データとインフラストラクチャに対する最大限のコントロールを必要とする組織に最適化されています。

*   **展開**: AIGNE Hub は、自社のプライベートクラウドまたはオンプレミスのデータセンター内に展開されます。
*   **請求**: 組織は、リソース消費に対して AI プロバイダーに直接支払います。すべての請求および使用状況データは、外部のサービスプロバイダーの関与なしに、内部で管理されます。
*   **データプライバシー**: プロンプト、レスポンス、API キーを含むすべてのデータは、ネットワーク境界内に留まり、データ主権およびプライバシー規制への準拠を保証します。
*   **ユースケース**: 内部開発チーム、企業の AI イニシアチブ、および厳格なデータセキュリティ要件を持つ組織に最適です。

### サービスプロバイダーモード

このモデルでは、外部の顧客に AI サービスを提供し、AIGNE Hub をマルチテナントの収益創出プラットフォームへと変えることができます。

*   **展開**: パブリックまたはプライベートクラウドに展開可能で、マルチテナンシー向けに設定されています。
*   **請求**: Payment Kit と統合された内蔵のクレジットシステムを活用して、顧客の請求を管理します。カスタム価格設定、利益率の定義、スタータークレジットによるユーザーのオンボーディングの自動化が可能です。
*   **管理**: 顧客アカウントの管理、使用状況の追跡、請求サイクルの処理のための包括的なツールスイートを提供します。
*   **ユースケース**: AI サービスプロバイダー、SaaS プラットフォーム、および厳選された AI モデルへのアクセスを収益化しようとしているビジネスに最適です。
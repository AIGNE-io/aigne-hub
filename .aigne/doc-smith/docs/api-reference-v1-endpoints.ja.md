# API リファレンス

このドキュメントでは、AIGNE Hub API のアーキテクチャ、エンドポイント、および運用上の動作に焦点を当て、詳細なリファレンスを提供します。これは、サービスのデプロイと管理を担当する DevOps、SRE、およびインフラストラクチャチームを対象としています。

## システムアーキテクチャ

AIGNE Hub API は、さまざまな AI サービスのための堅牢なマルチプロバイダーゲートウェイとして設計されています。チャット補完、埋め込み、画像生成のための統一されたインターフェースを提供し、異なる基盤となる AI プロバイダーの管理の複雑さを抽象化します。

### プロバイダーの抽象化と認証情報管理

API の中心的な設計原則は、複数の AI プロバイダー（例：OpenAI、Bedrock）とシームレスに接続できる能力です。これはプロバイダー抽象化レイヤーを通じて実現されます。

-   **動的な認証情報読み込み**: システムは、安全なストアからさまざまなプロバイダーの認証情報を動的に読み込みます。リクエストがモデル（例：`openai/gpt-4`）を指定すると、API はプロバイダー（`openai`）を特定し、必要な認証情報を取得します。
-   **認証情報のローテーション**: API は単一のプロバイダーに対して複数の認証情報をサポートし、自動的にローテーションします。アクティブな認証情報を循環させるために `getNextAvailableCredential` 戦略を使用し、セキュリティと可用性の両方を向上させます。これにより、レートリミットの分散とゼロダウンタイムでのキーローテーションが可能になります。
-   **設定**: AI プロバイダーとその認証情報は、システムのデータベース内で `AiProvider` および `AiCredential` モデルを介して管理されます。これにより、管理者はコードを変更することなく、プロバイダーの詳細を追加、無効化、または更新できます。

### 回復性とエラーハンドリング

高可用性を確保するため、API はアップストリームのプロバイダーリクエストに対する自動リトライメカニズムを組み込んでいます。

-   **リトライロジック**: システムは、重要なエンドポイントに対して `createRetryHandler` を使用します。基盤となる AI プロバイダーへのリクエストがリトライ可能なステータスコード（`429 Too Many Requests`、`500 Internal Server Error`、`502 Bad Gateway`）で失敗した場合、API は自動的にリクエストを再試行します。
-   **設定可能性**: 最大リトライ回数は `maxRetries` 環境変数を介して設定可能であり、運用者はニーズに応じてシステムの回復性を調整できます。

### 認証

API エンドポイントは、コンポーネントベースの認証メカニズム（`ensureRemoteComponentCall` および `ensureComponentCall`）によって保護されています。これにより、エコシステム内の承認されたサービスまたはコンポーネントのみが API にアクセスできることが保証され、通常は公開鍵ベースの検証システムが使用されます。

## エンドポイント

以下のセクションでは、利用可能な API エンドポイントについて詳しく説明します。すべてのエンドポイントには `/v1` というプレフィックスが付きます。

---

### チャット補完

このエンドポイントは、与えられたチャットの会話やプロンプトに対する応答を生成します。標準レスポンスとストリーミングレスポンスの両方をサポートしています。

`POST /v1/chat/completions`
`POST /v1/completions`

**リクエストボディ**

| フィールド | タイプ | 説明 | 必須 |
| :--- | :--- | :--- | :--- |
| `model` | string | 使用するモデルの ID（例：`openai/gpt-4`、`google/gemini-pro`）。 | はい |
| `messages` | array | 会話履歴を表すメッセージオブジェクトの配列。以下のオブジェクト構造を参照してください。 | はい（または `prompt`） |
| `prompt` | string | 単一のプロンプト文字列。`messages: [{ "role": "user", "content": "..." }]` の省略形です。 | はい（または `messages`） |
| `stream` | boolean | `true` の場合、レスポンスはサーバー送信イベントストリームとして送信されます。 | いいえ |
| `temperature` | number | ランダム性を制御します。0 から 2 の間の値。値が高いほど出力がランダムになります。 | いいえ |
| `topP` | number | ニュークリアスサンプリング。0.1 から 1 の間の値。モデルは `topP` の確率質量を持つトークンを考慮します。 | いいえ |
| `maxTokens` | integer | 補完で生成するトークンの最大数。 | いいえ |
| `presencePenalty` | number | -2.0 から 2.0 の間の値。正の値は、これまでのテキストに出現したかどうかに基づいて新しいトークンにペナルティを与えます。 | いいえ |
| `frequencyPenalty` | number | -2.0 から 2.0 の間の値。正の値は、これまでのテキストにおける既存の頻度に基づいて新しいトークンにペナルティを与えます。 | いいえ |
| `tools` | array | モデルが呼び出す可能性のあるツールのリスト。 | いいえ |
| `toolChoice` | string or object | モデルがどのツールを使用すべきかを制御します。"none"、"auto"、"required"、または関数を指定できます。 | いいえ |
| `responseFormat` | object | 出力形式を指定します。JSON モードの場合、`{ "type": "json_object" }` を使用します。 | いいえ |

**メッセージオブジェクトの構造** (`messages` 配列)

| フィールド | タイプ | 説明 |
| :--- | :--- | :--- |
| `role` | string | メッセージ作成者の役割。`system`、`user`、`assistant`、または `tool` のいずれか。 |
| `content` | string or array | メッセージの内容。文字列、またはマルチモーダル入力（例：テキストと画像）用の配列にすることができます。 |
| `toolCalls` | array | `assistant` ロールの場合、モデルによって行われたツールコールのリスト。 |
| `toolCallId` | string | `tool` ロールの場合、このメッセージが応答するツールコールの ID。 |

**レスポンス（非ストリーミング）**

-   `Content-Type: application/json`
-   レスポンスは、アシスタントの返信を含む JSON オブジェクトです。

```json
{
  "role": "assistant",
  "content": "This is the generated response.",
  "text": "This is the generated response.",
  "toolCalls": [],
  "usage": {
    "promptTokens": 5,
    "completionTokens": 10,
    "totalTokens": 15,
    "aigneHubCredits": 0.00015
  }
}
```

**レスポンス（ストリーミング）**

-   `Content-Type: text/event-stream`
-   レスポンスはサーバー送信イベントのストリームです。各イベントは、補完のチャンクを表す JSON オブジェクトです。最後のイベントには使用状況の統計が含まれる場合があります。

---

### 埋め込み

このエンドポイントは、与えられた入力のベクトル表現を作成します。これは、セマンティック検索、クラスタリング、その他の機械学習タスクに使用できます。

`POST /v1/embeddings`

**リクエストボディ**

| フィールド | タイプ | 説明 | 必須 |
| :--- | :--- | :--- | :--- |
| `model` | string | 使用する埋め込みモデルの ID（例：`openai/text-embedding-ada-002`）。 | はい |
| `input` | string or array | 埋め込む入力テキストまたはトークン。単一の文字列、または文字列/トークンの配列にすることができます。 | はい |

**レスポンス**

-   `Content-Type: application/json`
-   レスポンスには、埋め込みデータと使用状況情報が含まれます。

```json
{
  "data": [
    {
      "embedding": [ -0.00692, -0.0053, ... ],
      "index": 0,
      "object": "embedding"
    }
  ],
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

---

### 画像生成

このエンドポイントは、テキストプロンプトから画像を生成します。

`POST /v1/image/generations`

**リクエストボディ**

| フィールド | タイプ | 説明 | 必須 |
| :--- | :--- | :--- | :--- |
| `model` | string | 使用する画像生成モデルの ID（例：`dall-e-2`、`dall-e-3`）。 | はい |
| `prompt` | string | 希望する画像のテキスト説明。 | はい |
| `n` | integer | 生成する画像の数。1 から 10 の間でなければなりません。デフォルトは 1 です。 | いいえ |
| `size` | string | 生成される画像のサイズ（例：`1024x1024`、`1792x1024`）。 | いいえ |
| `responseFormat` | string | 生成された画像が返される形式。`url` または `b64_json` が指定できます。デフォルトは `url` です。 | いいえ |
| `quality` | string | 生成する画像の品質。`standard` または `hd` が指定できます。 | いいえ |

**レスポンス**

-   `Content-Type: application/json`
-   レスポンスには、生成された画像の URL または base64 エンコードされた JSON と、使用状況データが含まれます。

```json
{
  "images": [
    { "url": "https://..." },
    { "b64Json": "..." }
  ],
  "data": [ /* same as images */ ],
  "model": "dall-e-3",
  "usage": {
    "aigneHubCredits": 0.04
  }
}
```

---

### 音声サービス（プロキシ）

音声文字起こしと音声合成のエンドポイントは、OpenAI v1 API への直接のプロキシです。AIGNE Hub API は、リクエストを転送する前に、管理下の認証情報ストアから適切な API キーを挿入して認証を処理します。

リクエストとレスポンスの形式については、公式の OpenAI API ドキュメントを参照してください。

-   **音声文字起こし**: `POST /v1/audio/transcriptions`
-   **音声合成**: `POST /v1/audio/speech`

---

### システムステータス

このエンドポイントは、サービスが実行中であり、少なくとも 1 つの AI プロバイダーの API キーが設定されていることを確認するための簡単なヘルスチェックを提供します。

`GET /v1/status`

**レスポンス**

-   `Content-Type: application/json`

```json
{
  "available": true
}
```

-   `available`: 1 つ以上の API キーが設定され、使用可能かどうかを示すブール値。
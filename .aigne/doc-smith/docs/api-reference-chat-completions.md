# Chat Completions

This document provides a detailed specification for the Chat Completions API endpoint. By following this guide, you will learn how to generate conversational AI responses, manage streaming, and utilize model-specific parameters for building robust applications. This endpoint is central to creating interactive, text-based experiences.

The Chat Completions API enables you to build applications that leverage large language models for a variety of conversational tasks. You provide a series of messages as input, and the model returns a text-based response.

<!-- DIAGRAM_IMAGE_START:sequence:16:9 -->
![Chat Completions](assets/diagram/chat-completions-diagram-0.jpg)
<!-- DIAGRAM_IMAGE_END -->

For related functionalities, refer to the [Image Generation](./api-reference-image-generation.md) and [Embeddings](./api-reference-embeddings.md) API documentation.

## Create Chat Completion

Creates a model response for the given chat conversation.

`POST /api/chat/completions`

### Request Body

<x-field-group>
  <x-field data-name="model" data-type="string" data-required="true" data-default="gpt-3.5-turbo">
    <x-field-desc markdown>ID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API.</x-field-desc>
  </x-field>
  <x-field data-name="messages" data-type="array" data-required="true">
    <x-field-desc markdown>A list of messages comprising the conversation so far. See below for the message object structure.</x-field-desc>
    <x-field data-name="message" data-type="object">
      <x-field-desc markdown>Each message object must have a `role` and `content`.</x-field-desc>
      <x-field data-name="role" data-type="string" data-required="true">
        <x-field-desc markdown>The role of the message's author. Can be `system`, `user`, `assistant`, or `tool`.</x-field-desc>
      </x-field>
      <x-field data-name="content" data-type="string or array" data-required="true">
        <x-field-desc markdown>The content of the message. This can be a string or an array of content parts for multimodal models (e.g., text and image URLs).</x-field-desc>
      </x-field>
      <x-field data-name="name" data-type="string" data-required="false">
        <x-field-desc markdown>An optional name for the participant. Provides the model with context about the author of the message.</x-field-desc>
      </x-field>
      <x-field data-name="tool_calls" data-type="array" data-required="false">
        <x-field-desc markdown>The tool calls generated by the model, such as function calls.</x-field-desc>
      </x-field>
      <x-field data-name="tool_call_id" data-type="string" data-required="false">
        <x-field-desc markdown>Required if the role is `tool`. The ID of the tool call that this message is responding to.</x-field-desc>
      </x-field>
    </x-field>
  </x-field>
  <x-field data-name="temperature" data-type="number" data-required="false" data-default="1">
    <x-field-desc markdown>Controls randomness. Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Range: `0` to `2`.</x-field-desc>
  </x-field>
  <x-field data-name="top_p" data-type="number" data-required="false" data-default="1">
    <x-field-desc markdown>Controls diversity via nucleus sampling. `0.5` means half of all likelihood-weighted options are considered. Range: `0.1` to `1`.</x-field-desc>
  </x-field>
  <x-field data-name="stream" data-type="boolean" data-required="false" data-default="false">
    <x-field-desc markdown>If set to `true`, partial message deltas will be sent as server-sent events. The stream terminates with a `data: [DONE]` message.</x-field-desc>
  </x-field>
  <x-field data-name="max_tokens" data-type="integer" data-required="false">
    <x-field-desc markdown>The maximum number of tokens to generate. The total length of input tokens and generated tokens is limited by the model's context length.</x-field-desc>
  </x-field>
  <x-field data-name="presence_penalty" data-type="number" data-required="false" data-default="0">
    <x-field-desc markdown>Number between `-2.0` and `2.0`. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.</x-field-desc>
  </x-field>
  <x-field data-name="frequency_penalty" data-type="number" data-required="false" data-default="0">
    <x-field-desc markdown>Number between `-2.0` and `2.0`. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.</x-field-desc>
  </x-field>
  <x-field data-name="tools" data-type="array" data-required="false">
    <x-field-desc markdown>A list of tools the model may call. Currently, only functions are supported as a tool.</x-field-desc>
  </x-field>
  <x-field data-name="tool_choice" data-type="string or object" data-required="false">
    <x-field-desc markdown>Controls which (if any) tool is called by the model. Can be `'none'`, `'auto'`, `'required'`, or an object specifying a function to call.</x-field-desc>
  </x-field>
  <x-field data-name="response_format" data-type="object" data-required="false">
    <x-field-desc markdown>An object specifying the format that the model must output. Setting to `{ "type": "json_object" }` enables JSON mode.</x-field-desc>
  </x-field>
</x-field-group>

### Examples

#### Basic Request

This example demonstrates a simple conversation with the model.

```bash cURL Request icon=lucide:terminal
curl --location 'https://your-aigne-hub-instance.com/api/chat/completions' \
--header 'Authorization: Bearer YOUR_API_KEY' \
--header 'Content-Type: application/json' \
--data '{
    "model": "gpt-3.5-turbo",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": "Hello! Can you explain what AIGNE Hub is in simple terms?"
        }
    ]
}'
```

#### Streaming Request

To receive the response as a stream of events, set the `stream` parameter to `true`.

```bash cURL Stream Request icon=lucide:terminal
curl --location 'https://your-aigne-hub-instance.com/api/chat/completions' \
--header 'Authorization: Bearer YOUR_API_KEY' \
--header 'Content-Type: application/json' \
--header 'Accept: text/event-stream' \
--data '{
    "model": "gpt-3.5-turbo",
    "messages": [
        {
            "role": "user",
            "content": "Write a short story about a robot who discovers music."
        }
    ],
    "stream": true
}'
```

### Response Body

#### Standard Response

A standard JSON object is returned when `stream` is `false` or not set.

<x-field-group>
  <x-field data-name="role" data-type="string" data-desc="The role of the author of this message, always 'assistant'."></x-field>
  <x-field data-name="content" data-type="string" data-desc="The content of the message generated by the model."></x-field>
  <x-field data-name="tool_calls" data-type="array" data-required="false" data-desc="The tool calls generated by the model, if any."></x-field>
</x-field-group>

**Example Standard Response**

```json Response Body
{
  "role": "assistant",
  "content": "AIGNE Hub is a centralized gateway that manages interactions with various AI models from different providers. It simplifies API access, handles billing and credits, and provides analytics on usage and costs, acting as a single point of control for an organization's AI services."
}
```

#### Streaming Response

When `stream` is `true`, the API returns a stream of `text/event-stream` chunks. Each chunk is a JSON object.

<x-field-group>
  <x-field data-name="delta" data-type="object" data-desc="A chunk of the message delta.">
    <x-field data-name="role" data-type="string" data-required="false" data-desc="The role of the author, typically 'assistant'."></x-field>
    <x-field data-name="content" data-type="string" data-required="false" data-desc="A partial content of the message."></x-field>
    <x-field data-name="tool_calls" data-type="array" data-required="false" data-desc="Partial tool call information."></x-field>
  </x-field>
  <x-field data-name="usage" data-type="object" data-desc="Present in the final chunk, contains token usage statistics.">
    <x-field data-name="prompt_tokens" data-type="integer" data-desc="Number of tokens in the prompt."></x-field>
    <x-field data-name="completion_tokens" data-type="integer" data-desc="Number of tokens in the generated completion."></x-field>
    <x-field data-name="total_tokens" data-type="integer" data-desc="Total number of tokens used in the request."></x-field>
  </x-field>
</x-field-group>

**Example Stream Chunks**

```text Event Stream
data: {"delta":{"role":"assistant","content":"Unit "}}

data: {"delta":{"content":"734,"}}

data: {"delta":{"content":" a sanitation "}}

data: {"delta":{"content":"and maintenance "}}

data: {"delta":{"content":"robot, hummed..."}}

data: {"usage":{"promptTokens":15,"completionTokens":100,"totalTokens":115}}

data: [DONE]
```

## Summary

The Chat Completions endpoint is a powerful tool for integrating conversational AI into your applications. It offers flexibility through various parameters, including streaming and tool use, to support a wide range of use cases.

For more information on other available API endpoints, please refer to the following documents:

<x-cards data-columns="2">
  <x-card data-title="Image Generation" data-icon="lucide:image" data-href="/api-reference/image-generation">
    Learn how to generate and manipulate images using AI models.
  </x-card>
  <x-card data-title="Embeddings" data-icon="lucide:bot" data-href="/api-reference/embeddings">
    Understand how to create vector representations of text for machine learning tasks.
  </x-card>
</x-cards>